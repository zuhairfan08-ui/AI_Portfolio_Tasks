# AI & ML Portfolio Tasks

This repository contains **5 AI/ML projects** showcasing practical applications of Large Language Models (LLMs) and machine learning techniques. Each task demonstrates a different skill set, from text classification and predictive modeling to context-aware chatbots and automated ticket tagging.
# Task List
# Task 1: BERT News Classifier
- **File:** `Task1_BERT_News_Classifier.ipynb`
- **Objective:** Classify news articles into categories using BERT.
- **Dataset:** News dataset with labeled categories.
- **Skills Gained:**
  - Text preprocessing for NLP
  - Fine-tuning pre-trained BERT model
  - Evaluation using accuracy, F1-score
- **Key Results:** High classification accuracy with BERT-based embeddings.
# Task 2: ML Pipeline
- **File:** `Task2_ML_Pipeline.ipynb`
- **Objective:** Build a complete ML pipeline for data preprocessing, modeling, and evaluation.
- **Dataset:** Structured dataset (example: tabular data).
- **Skills Gained:**
  - Data preprocessing and feature engineering
  - Model selection and training
  - Evaluation with metrics like RMSE, accuracy
- **Key Results:** Automated pipeline improves efficiency and reproducibility of ML workflows.
# Task 3: Multimodal Housing Price Prediction
- **File:** `Task3_Multimodal_Housing_Price.ipynb`
- **Objective:** Predict housing prices using both structured and unstructured (image) data.
- **Dataset:** Housing dataset with features and images.
- **Skills Gained:**
  - Multimodal data handling (tabular + image)
  - CNNs for image feature extraction
  - Regression models for price prediction
- **Key Results:** Accurate housing price predictions using combined features.
# Task 4: Context-Aware Chatbot using RAG
- **File:** `Task4_Context_Aware_Chatbot_RAG.ipynb`
- **Objective:** Build a chatbot that remembers conversation context and retrieves information from a document store.
- **Dataset:** Custom corpus (e.g., Wikipedia pages, internal documents)
- **Skills Gained:**
  - Retrieval-Augmented Generation (RAG)
  - Conversational memory using LLMs
  - Vector search with embeddings
  - Deployment with Streamlit
- **Key Results:** Chatbot capable of answering questions using context-aware retrieval.
# Task 5: Auto-Tagging Support Tickets using LLM
- **File:** `Task5_Auto_Tagging_Support_Tickets_Using_LLM.ipynb`
- **Objective:** Automatically categorize support tickets using a language model.
- **Dataset:** Free-text support ticket dataset
- **Skills Gained:**
  - Prompt engineering
  - Zero-shot & few-shot classification
  - Multi-class prediction and ranking
- **Key Results:** Automatically generates top 3 tags per ticket with high accuracy.
# Repository Guidelines
- Each notebook is structured to include:
  1. Problem Statement & Objective
  2. Dataset Loading & Preprocessing
  3. Model Development & Training
  4. Evaluation & Metrics
  5. Visualizations (if applicable)
  6. Final Summary & Insights
- Clear code comments for understanding workflow.
- All notebooks are ready to run independently.


## **How to Use**
1. Clone the repository:
   ```bash
   git clone https://github.com/<your-username>/<repo-name>.git
